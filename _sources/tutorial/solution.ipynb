{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be02fd3a",
   "metadata": {},
   "source": [
    "# Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f498c2b",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dmri_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a662488204c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mdmri_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdmri_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://files.osf.io/v1/resources/8k95s/providers/osfstorage/6070b4c2f6585f03fb6123a2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dmri_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tempfile import mkstemp\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "if dmri_dataset._filepath.exists():\n",
    "    dmri_dataset._filepath.unlink()\n",
    "url = \"https://files.osf.io/v1/resources/8k95s/providers/osfstorage/6070b4c2f6585f03fb6123a2\"\n",
    "datapath = Path(mkstemp(suffix=\".h5\")[1])\n",
    "if datapath.stat().st_size == 0:\n",
    "    datapath.write_bytes(\n",
    "        requests.get(url, allow_redirects=True).content\n",
    "    )\n",
    "\n",
    "dmri_dataset = DWI.from_filename(datapath)\n",
    "dmri_dataset.dataobj = dmri_dataset.dataobj[..., :32]\n",
    "dmri_dataset.gradients = dmri_dataset.gradients[..., :32]\n",
    "datapath.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9bb1e",
   "metadata": {},
   "source": [
    "Once we have finalized the main components of the solution, it is time for integration.\n",
    "We now want to iterate over all the *LOGO* partitions of the dataset, generate a synthetic reference through the model of choice, and finally estimate the misalignment between the left-out gradient and the synthetic reference.\n",
    "This solution, must also abide by the API we have envisioned.\n",
    "\n",
    "```{admonition} Exercise\n",
    "Complete the code snipet below to integrate the different components into the final solution to the dMRI head-motion problem.\n",
    "```\n",
    "\n",
    "```python\n",
    "class EddyMotionEstimator:\n",
    "    \"\"\"Estimates rigid-body head-motion and distortions derived from eddy-currents.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fit(\n",
    "        dwdata,\n",
    "        *,\n",
    "        n_iter=1,\n",
    "        align_kwargs=None,\n",
    "        model=\"b0\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        Estimate head-motion and Eddy currents.\n",
    "\n",
    "        <please write a descriptive documentation of the function here>\n",
    "\n",
    "        \"\"\"\n",
    "        align_kwargs = align_kwargs or {}\n",
    "\n",
    "        if dwdata.brainmask is not None:\n",
    "            kwargs[\"mask\"] = dwdata.brainmask\n",
    "\n",
    "        kwargs[\"S0\"] = dwdata.bzero\n",
    "\n",
    "        for i_iter in range(1, n_iter + 1):\n",
    "            for i in np.arange(len(dwdata)):\n",
    "                # run a original-to-synthetic affine registration\n",
    "                with TemporaryDirectory() as tmpdir:\n",
    "                    # Invoke `dwdata.logo_split()` on an index.\n",
    "                    data_train, data_test = ...\n",
    "\n",
    "                    # Factory creates the appropriate model and pipes arguments\n",
    "                    dwmodel = ...\n",
    "\n",
    "                    # fit the model\n",
    "\n",
    "\n",
    "                    # generate a synthetic dw volume for the test gradient\n",
    "                    predicted = ...\n",
    "\n",
    "                    # Write arrays in memory to harddisk as NIfTI files\n",
    "                    tmpdir = Path(tmpdir)\n",
    "                    moving = tmpdir / \"moving.nii.gz\"\n",
    "                    fixed = tmpdir / \"fixed.nii.gz\"\n",
    "                    _to_nifti(data_test[0], moving)\n",
    "                    _to_nifti(predicted, fixed)\n",
    "\n",
    "                    # Prepare ANTs' antsRegistration via NiPype\n",
    "                    registration = Registration(\n",
    "                        fixed_image=str(fixed.absolute()),\n",
    "                        moving_image=str(moving.absolute()),\n",
    "                        **align_kwargs,\n",
    "                    )\n",
    "\n",
    "                    # execute ants command line\n",
    "                    result = registration.run(cwd=str(tmpdir)).outputs\n",
    "\n",
    "                    # read output transform\n",
    "                    xform = nt.io.itk.ITKLinearTransform.from_filename(\n",
    "                        result.forward_transforms[0]\n",
    "                    )\n",
    "\n",
    "                # update\n",
    "                dwdata.set_transform(i, xform)\n",
    "\n",
    "        return dwdata.em_affines\n",
    "```\n",
    "\n",
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8786e4",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "class EddyMotionEstimator:\n",
    "    \"\"\"Estimates rigid-body head-motion and distortions derived from eddy-currents.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def fit(\n",
    "        dwdata,\n",
    "        *,\n",
    "        n_iter=1,\n",
    "        align_kwargs=None,\n",
    "        model=\"b0\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        Estimate head-motion and Eddy currents.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dwdata : :obj:`~eddymotion.dmri.DWI`\n",
    "            The target DWI dataset, represented by this tool's internal\n",
    "            type. The object is used in-place, and will contain the estimated\n",
    "            parameters in its ``em_affines`` property, as well as the rotated\n",
    "            *b*-vectors within its ``gradients`` property.\n",
    "        n_iter : :obj:`int`\n",
    "            Number of iterations this particular model is going to be repeated.\n",
    "        align_kwargs : :obj:`dict`\n",
    "            Parameters to configure the image registration process.\n",
    "        model : :obj:`str`\n",
    "            Selects the diffusion model that will generate the registration target\n",
    "            corresponding to each gradient map.\n",
    "            See :obj:`~eddymotion.model.ModelFactory` for allowed models (and corresponding\n",
    "            keywords).\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        affines : :obj:`list` of :obj:`numpy.ndarray`\n",
    "            A list of :math:`4 \\times 4` affine matrices encoding the estimated\n",
    "            parameters of the deformations caused by head-motion and eddy-currents.\n",
    "\n",
    "        \"\"\"\n",
    "        align_kwargs = align_kwargs or {}\n",
    "\n",
    "        if dwdata.brainmask is not None:\n",
    "            kwargs[\"mask\"] = dwdata.brainmask\n",
    "\n",
    "        kwargs[\"S0\"] = dwdata.bzero\n",
    "\n",
    "        for i_iter in range(1, n_iter + 1):\n",
    "            for i in np.arange(len(dwdata)):\n",
    "                # run a original-to-synthetic affine registration\n",
    "                with TemporaryDirectory() as tmpdir:\n",
    "                    # Invoke `dwdata.logo_split()` on an index.\n",
    "                    data_train, data_test = dwdata.logo_split(i, with_b0=True)\n",
    "\n",
    "                    # Factory creates the appropriate model and pipes arguments\n",
    "                    dwmodel = ModelFactory.init(\n",
    "                        gtab=data_train[1], model=model, **kwargs\n",
    "                    )\n",
    "\n",
    "                    # fit the model\n",
    "                    dwmodel.fit(data_train[0])\n",
    "\n",
    "                    # generate a synthetic dw volume for the test gradient\n",
    "                    predicted = dwmodel.predict(data_test[1])\n",
    "\n",
    "                    # Write arrays in memory to harddisk as NIfTI files\n",
    "                    tmpdir = Path(tmpdir)\n",
    "                    moving = tmpdir / \"moving.nii.gz\"\n",
    "                    fixed = tmpdir / \"fixed.nii.gz\"\n",
    "                    _to_nifti(data_test[0], moving)\n",
    "                    _to_nifti(predicted, fixed)\n",
    "\n",
    "                    # Prepare ANTs' antsRegistration via NiPype\n",
    "                    registration = Registration(\n",
    "                        fixed_image=str(fixed.absolute()),\n",
    "                        moving_image=str(moving.absolute()),\n",
    "                        **align_kwargs,\n",
    "                    )\n",
    "\n",
    "                    # execute ants command line\n",
    "                    result = registration.run(cwd=str(tmpdir)).outputs\n",
    "\n",
    "                    # read output transform\n",
    "                    xform = nt.io.itk.ITKLinearTransform.from_filename(\n",
    "                        result.forward_transforms[0]\n",
    "                    )\n",
    "\n",
    "                # update\n",
    "                dwdata.set_transform(i, xform)\n",
    "\n",
    "        return dwdata.em_affines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83b619",
   "metadata": {},
   "source": [
    "The above code allows us to use our estimator as follows:\n",
    "\n",
    "```python\n",
    "from eddymotion.estimator import EddyMotionEstimator\n",
    "\n",
    "estimated_affines = EddyMotionEstimator.fit(dmri_dataset, model=\"b0\")\n",
    "```\n",
    "\n",
    "## What's next? - Testing!\n",
    "\n",
    "Once we have our first implementation functional, we should think of some unit-tests for our code.\n",
    "\n",
    "```{admonition} Exercise\n",
    "Write a unit test for the `TrivialB0Model`.\n",
    "This test would just make sure that, regardless of the particular partition of the input dataset, a *b=0* map is always returned.\n",
    "```\n",
    "\n",
    "**Solution**: in this solution, we are using `pytest` to integrate the test into a higher-level test suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d57c95",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\"split_index\", list(range(30)))\n",
    "def test_TrivialB0Model(split_index, dmri_dataset):\n",
    "    model = TrivialB0Model(\n",
    "        dmri_dataset.gradients,\n",
    "        S0=dmri_dataset.bzero,\n",
    "    )\n",
    "    data_train, data_test = dmri_dataset.logo_split(split_index)\n",
    "    model.fit(data_train[0])\n",
    "    predicted = model.predict(data_test[1])\n",
    "\n",
    "    assert np.all(dmri_dataset.bzero == predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6faf9",
   "metadata": {},
   "source": [
    "## And after testing? - Validation!\n",
    "\n",
    "Once we have a sufficient portion of our code *covered* by unit-tests, then we would add some *integration* tests that give us confidence that our bullet-proof individual components also work together.\n",
    "Only after we have both steps secure, we can run benchmarks and evaluations from which we learn whether our solution works, and characterize its limitations.\n",
    "\n",
    "The main strategy to validate this software would entail finding/acquiring a special dataset where motion is not present or extremely low, in which we *introduce* a known head-motion pattern with which we are going to challenge our estimator.\n",
    "Some ideas to achieve this are:\n",
    "\n",
    "- a dataset acquired with special sequences that can do prospective motion correction, or\n",
    "- a dataset that has been acquired under very controlled settings, with an extremely collaborative participant who was also wearing a personalized mold, or\n",
    "- a fully synthetic dataset such as the Fiber Box, or\n",
    "- a fully synthetic dataset containing a repeated *b=0* image (this evaluation would be limited to work with the `TrivialB0Model`, for instance).\n",
    "\n",
    "***Please head to [the GitHub repository](https://github.com/nipreps/EddyMotionCorrection) and share your ideas with us! We are welcoming new contributors!***"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "source_map": [
   11,
   15,
   39,
   121,
   214,
   235,
   252
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}