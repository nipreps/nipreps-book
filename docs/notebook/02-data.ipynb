{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to dMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusion imaging probes the random, microscopic movement of water molecules by using MRI sequences that are sensitive to the geometry and environmental organization surrounding these protons.\n",
    "This is a popular technique for studying the white matter of the brain.\n",
    "The diffusion within biological structures, such as the brain, are often restricted due to barriers (e.g., cell membranes), resulting in a preferred direction of diffusion (anisotropy).\n",
    "A typical dMRI scan will acquire multiple volumes (or ***angular samples***), each sensitive to a particular ***diffusion direction***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"<video loop=\"yes\" muted=\"yes\" autoplay=\"yes\" controls=\"yes\"><source src=\"../assets/videos/dMRI-signal-movie.mp4\" type=\"video/mp4\"/></video>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sourced from Dr. A. Rokem, DIPY Workshop 2021*\n",
    "\n",
    "These *diffusion directions* (or ***orientations***) are a fundamental piece of metadata to interpret dMRI data, as models need to know the exact orientation of each angular sample.\n",
    "\n",
    "**Main elements of a dMRI dataset**\n",
    "\n",
    "- A 4D data array, where the last dimension encodes the reconstructed **diffusion direction *maps***.\n",
    "- Tabular data or a 2D array, listing the **diffusion directions** (`.bvec`) and the encoding **gradient strength** (`.bval`).\n",
    "\n",
    "In summary, dMRI involves ***complex data types*** that, as programmers, we want to access, query and manipulate with ease.\n",
    "\n",
    "## Python and object oriented programming\n",
    "\n",
    "Python is an [object oriented programming](https://en.wikipedia.org/wiki/Object-oriented_programming) language.\n",
    "It allows us to represent and encapsulate data types and corresponding behaviors into programming structures called *objects*.\n",
    "\n",
    "**Data structures**\n",
    "\n",
    "How you feed in data into your algorithm will impose constraints that might completely hinder the implementation of nonfunctional requirements down the line.\n",
    "Therefore, a careful plan must also be thought out for the data structures we are going to handle.\n",
    "\n",
    "Therefore, let's leverage Python to create *objects* that contain dMRI data.\n",
    "In Python, *objects* can be specified by defining a class.\n",
    "In the example code below, we've created a class with the name `DWI`.\n",
    "To simplify class creation, we've also used the magic of a Python library called [`attrs`](https://www.attrs.org/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Representing data in hard-disk and memory.\"\"\"\n",
    "import attr\n",
    "\n",
    "def _data_repr(value):\n",
    "    if value is None:\n",
    "        return \"None\"\n",
    "    return f\"<{'x'.join(str(v) for v in value.shape)} ({value.dtype})>\"\n",
    "\n",
    "\n",
    "@attr.s(slots=True)\n",
    "class DWI:\n",
    "    \"\"\"Data representation structure for dMRI data.\"\"\"\n",
    "\n",
    "    dataobj = attr.ib(default=None, repr=_data_repr)\n",
    "    \"\"\"A numpy ndarray object for the data array, without *b=0* volumes.\"\"\"\n",
    "    brainmask = attr.ib(default=None, repr=_data_repr)\n",
    "    \"\"\"A boolean ndarray object containing a corresponding brainmask.\"\"\"\n",
    "    bzero = attr.ib(default=None, repr=_data_repr)\n",
    "    \"\"\"A *b=0* reference map, preferably obtained by some smart averaging.\"\"\"\n",
    "    gradients = attr.ib(default=None, repr=_data_repr)\n",
    "    \"\"\"A 2D numpy array of the gradient table in RAS+B format.\"\"\"\n",
    "    em_affines = attr.ib(default=None)\n",
    "    \"\"\"\n",
    "    List of :obj:`nitransforms.linear.Affine` objects that bring\n",
    "    DWIs (i.e., no b=0) into alignment.\n",
    "    \"\"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Obtain the number of high-*b* orientations.\"\"\"\n",
    "        return self.gradients.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements several *attributes* as well as a *behavior* - the `__len__` *method*.\n",
    "The `__len__` method is special in Python, as it will be executed when we call the built-in function `len()` on our object.\n",
    "\n",
    "Let's test out the `DWI` data structure with some *simulated* data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy is a fundamental Python library for working with arrays\n",
    "import numpy as np\n",
    "\n",
    "# create a new DWI object, with only gradient information that is random\n",
    "dmri_dataset = DWI(gradients=np.random.normal(size=(4, 64)))\n",
    "\n",
    "# call Python's built-in len() function\n",
    "print(len(dmri_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this `print()` statement is telling us that this (simulated) dataset has 64 diffusion-weighted samples.\n",
    "\n",
    "## Using the new data representation object\n",
    "\n",
    "The code shown above was just a snippet of the `DWI` class. For simplicity, we will be using the full implementation of this class from our [`eddymotion` package](https://github.com/nipreps/EddyMotionCorrection/blob/main/eddymotion/dmri.py)\n",
    "Under the `data/` folder of this book's distribution, we have stored a sample DWI dataset with filename `dwi.h5`.\n",
    "Please note that the file has been minimized by zeroing all but two diffusion-weighted orientation maps.\n",
    "\n",
    "Let's get some insights from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class from the library\n",
    "from eddymotion.dmri import DWI\n",
    "\n",
    "# load the sample file\n",
    "dmri_dataset = DWI.from_filename(\"../../data/dwi.h5\")\n",
    "print(len(dmri_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the dataset is reporting to have 102 diffusion-weighted samples.\n",
    "\n",
    "Python will automatically generate a summary of this object if we just type the name of our new object.\n",
    "This pretty-printing of the object informs us about the data and metadata that, together, compose this particular DWI dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmri_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll go over some of the components of `dmri_dataset` through this lesson.\n",
    "\n",
    "## Visualizing the data\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Let's start out by seeing what the data looks like.\n",
    "The fully-fledged `DWI` object has a convenience function to plot the dataset.\n",
    "\n",
    "Hint: To see all of the instances and behaviors available to an object, try typing the object name, followed by `.` and <kbd>Tab</kbd>\n",
    "\n",
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "dmri_dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling `plot_mosaic()` without any arguments, the *b=0* reference is plotted.\n",
    "This *b=0* reference is a map of the signal measured ***without gradient sensitization***, or in other words, when we are not measuring diffusion in any direction.\n",
    "The *b=0* map can be used by diffusion modeling as the reference to quantify the signal drop at every voxel and given a particular orientation gradient.\n",
    "\n",
    "We can also get some insight into how a particular diffusion-weighted orientation looks like by selecting them with the argument `index`.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Try calling `plot_mosaic` with an index of 10 or 100.\n",
    "\n",
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusion that exhibits directionality in the same direction as the gradient results in a loss of signal.\n",
    "As we can see, ***diffusion-weighted*** images consistently drop almost all signal in voxels filled with cerebrospinal fluid because there, water diffusion is free (isotropic) regardless of the direction that is being measured.\n",
    "\n",
    "We can also see that the images at `index=10` and `index=100` have different gradient strength (\"*b-value*\").\n",
    "The higher the magnitude of the gradient, the more diffusion that is allowed to occur, indicated by the overall decrease in signal intensity.\n",
    "Stronger gradients yield diffusion maps with substantially lower SNR (signal-to-noise ratio), as well as larger distortions derived from the so-called \"*Eddy-currents*\".\n",
    "\n",
    "## Visualizing the gradient information\n",
    "\n",
    "Our `DWI` object stores the gradient information in the `gradients` attribute.\n",
    "\n",
    "**Exercise**\n",
    "Let's see the shape of the gradient information.\n",
    "\n",
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a $4\\times102$ -- three spatial coordinates ($b_x$, $b_y$, $b_z$) of the unit-norm \"*b-vector*\", plus the gradient sensitization magnitude (the \"*b-value*\"), with a total of 102 different orientations for the case at hand.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Try printing the gradient information to see what it contains.\n",
    "Remember to transpose (`.T`) the array.\n",
    "\n",
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we'll refer to this array as the gradient table.\n",
    "\n",
    "It consists of one row per diffusion-weighted image, with each row consisting of 4 values corresponding to [ R A S+ b ].\n",
    "\n",
    "[ R A S+ ] are the components of the **gradient direction**.\n",
    "Note that the directions have been re-oriented with respect to *world space coordinates*.\n",
    "For more information on this, refer to {doc}`the Affine section in The extra mile <../extra/nifti>`.\n",
    "\n",
    "The last column, b, reflects the **timing and strength of the gradients** in units of s/mm².\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "To get a better sense of which gradient directions were sampled, let's plot them!\n",
    "\n",
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've projected all of the gradient directions onto the surface of a sphere, with each unique gradient strength colour-coded.\n",
    "Darkest hues correspond to the lowest *b*-values and brighter to the highest.\n",
    "\n",
    "## The *LOGO* (leave-one-gradient-out) splitter\n",
    "\n",
    "One final behavior that will make our endeavor easier in the long run is a convenience method for data splitting.\n",
    "In particular, we are implementing some sort of cross-validation scheme where we will iterate over different data splits.\n",
    "In this case, the splitting strategy is a simple leave-one-out.\n",
    "Because one \"*datapoint*\" in our DWI dataset corresponds to one gradient, we will refer to this partitioning of the dataset as *leave-one-gradient-out (LOGO)*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logo_split(self, index, with_b0=False):\n",
    "    \"\"\"\n",
    "    Produce one fold of LOGO (leave-one-gradient-out).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    index : :obj:`int`\n",
    "        Index of the DWI orientation to be left out in this fold.\n",
    "    with_b0 : :obj:`bool`\n",
    "        Insert the *b=0* reference at the beginning of the training dataset.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    (train_data, train_gradients) : :obj:`tuple`\n",
    "        Training DWI and corresponding gradients.\n",
    "        Training data/gradients come **from the updated dataset**.\n",
    "    (test_data, test_gradients) :obj:`tuple`\n",
    "        Test 3D map (one DWI orientation) and corresponding b-vector/value.\n",
    "        The test data/gradient come **from the original dataset**.\n",
    "\n",
    "    \"\"\"\n",
    "    dwframe = self.dataobj[..., index]\n",
    "    bframe = self.gradients[..., index]\n",
    "\n",
    "    # if the size of the mask does not match data, cache is stale\n",
    "    mask = np.zeros(len(self), dtype=bool)\n",
    "    mask[index] = True\n",
    "\n",
    "    train_data = self.dataobj[..., ~mask]\n",
    "    train_gradients = self.gradients[..., ~mask]\n",
    "\n",
    "    if with_b0:\n",
    "        train_data = np.concatenate(\n",
    "            (np.asanyarray(self.bzero)[..., np.newaxis], train_data),\n",
    "            axis=-1,\n",
    "        )\n",
    "        b0vec = np.zeros((4, 1))\n",
    "        b0vec[0, 0] = 1\n",
    "        train_gradients = np.concatenate(\n",
    "            (b0vec, train_gradients),\n",
    "            axis=-1,\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        (train_data, train_gradients),\n",
    "        (dwframe, bframe),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is contained in the `DWI` class shown earlier and will allow us to easily partition the dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eddymotion.viz import plot_dwi\n",
    "\n",
    "data_train, data_test = dmri_dataset.logo_split(10)\n",
    "plot_dwi(data_test[0], dmri_dataset.affine, gradient=data_test[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_train` is a tuple containing all diffusion-weighted volumes and the corresponding gradient table, excluding the left-out, which is stored in `data_test` (the 11<sup>th</sup> gradient indexed by `10`, in this example).\n",
    "`data_test[0]` contains the held-out diffusion-weighted volume and `data_test[1]`, the corresponding gradient table.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Try printing the shapes of elements in the `data_train` tuple.\n",
    "\n",
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Likewise for the left-out gradient, try printing the shapes of elements in the `data_test` tuple.\n",
    "\n",
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps: diffusion modeling\n",
    "\n",
    "By modeling the diffusion signal, the acquired images can provide measurements which are related to the microscopic changes and estimate white matter trajectories."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}